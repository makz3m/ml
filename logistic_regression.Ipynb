{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04697070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fa46df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logreg(ClassifierMixin):\n",
    "    def __init__(self, lr = 0.01, epochs = 200):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.e**(-z))\n",
    "    \n",
    "\n",
    "    def fit(self, X:np.ndarray, Y:np.ndarray, pos_class):\n",
    "        n, d = X.shape\n",
    "        self.w = np.random.random(d)\n",
    "        self.b = np.random.randint(0,5) \n",
    "        Y = (Y == pos_class).astype(int)\n",
    "        for _ in range(self.epochs):\n",
    "            idx = np.random.permutation(n)\n",
    "            for i in idx: \n",
    "                er = Y[i] - self.sigmoid(np.dot(self.w, X[i]) + self.b)\n",
    "                w_grad = - X[i] * er\n",
    "                b_grad = - er\n",
    "                self.w -= self.lr * w_grad\n",
    "                self.b -= self.lr * b_grad\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X:np.ndarray):\n",
    "        n,d = X.shape\n",
    "        ans = []\n",
    "        for i in range(n):\n",
    "            p = self.sigmoid(np.dot(X[i], self.w) + self.b)\n",
    "            ans.append(p)\n",
    "        return np.array(ans)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0a36f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, Y = load_iris()['data'], load_iris()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97bb06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# lr = logreg()\n",
    "# lr.fit(X_train, y_train)\n",
    "# pred = lr.predict(X_test)\n",
    "# mean_absolute_error(pred, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12907e",
   "metadata": {},
   "source": [
    "У нас получилось что-то работающее. Обобщим для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2b6bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20cd10a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71828183,  7.3890561 , 20.08553692])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "exponented = np.exp(a)\n",
    "exponented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class smax(ClassifierMixin):\n",
    "    def __init__(self, lr = 0.01, epochs = 200):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.logregs = {}\n",
    "\n",
    "\n",
    "    def fit(self, X:np.ndarray, Y:np.ndarray):\n",
    "        classes = set(Y)\n",
    "        self.logregs = {}\n",
    "        for cl in classes:\n",
    "            lg = logreg()\n",
    "            lg.fit(X,Y,cl)\n",
    "            self.logregs[cl] = lg\n",
    "        return self\n",
    "            \n",
    "    def softmax(self, a):\n",
    "        exponented = np.exp(a)\n",
    "        exp_sum = np.sum(exponented)\n",
    "        return exponented/exp_sum\n",
    "\n",
    "    def predict(self, X:np.ndarray, probas = False):\n",
    "        n, d = X.shape\n",
    "        ans = []\n",
    "        for i in range(n):\n",
    "            y = []\n",
    "            y_classes = []\n",
    "            for cl, lg in self.logregs.items():\n",
    "                y.append(float(lg.predict(X[i].reshape(1,-1))))\n",
    "                y_classes.append(int(cl))\n",
    "            y = [float(i) for i in list(self.softmax(y))]\n",
    "            res = dict(zip(y_classes, y))\n",
    "            ans.append(res)\n",
    "        if probas:\n",
    "            return ans\n",
    "        return [max(i, key=i.get) for i in ans]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40087f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\AppData\\Local\\Temp\\ipykernel_4648\\4096874229.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y.append(float(lg.predict(X[i].reshape(1,-1))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{0: 0.2619647972004547, 1: 0.4552178014731016, 2: 0.28281740132644373},\n",
       " {0: 0.5677491105487567, 1: 0.22220213733612973, 2: 0.21004875211511356},\n",
       " {0: 0.175856356877825, 1: 0.3465290104931324, 2: 0.4776146326290425},\n",
       " {0: 0.28920380969325715, 1: 0.3906369301832525, 2: 0.32015926012349044},\n",
       " {0: 0.26695658029323915, 1: 0.4572965947710886, 2: 0.27574682493567226},\n",
       " {0: 0.5631801043804077, 1: 0.22816950984156856, 2: 0.2086503857780237},\n",
       " {0: 0.3111123050665055, 1: 0.3813093466643938, 2: 0.3075783482691007},\n",
       " {0: 0.2613909756629575, 1: 0.28975527633837644, 2: 0.44885374799866595},\n",
       " {0: 0.22090276046055507, 1: 0.4539840362730244, 2: 0.32511320326642057},\n",
       " {0: 0.28265924604745923, 1: 0.4334259632312212, 2: 0.2839147907213196},\n",
       " {0: 0.26859028714549865, 1: 0.30425163786015846, 2: 0.42715807499434294},\n",
       " {0: 0.5402178306599166, 1: 0.2597440714964907, 2: 0.20003809784359278},\n",
       " {0: 0.5637831684326371, 1: 0.22835243656335164, 2: 0.20786439500401122},\n",
       " {0: 0.5433150652866329, 1: 0.25529647658271126, 2: 0.20138845813065592},\n",
       " {0: 0.5705350816716578, 1: 0.21889632121013164, 2: 0.2105685971182106},\n",
       " {0: 0.31254361733017305, 1: 0.3620903739161346, 2: 0.32536600875369226},\n",
       " {0: 0.20355116096604728, 1: 0.25055875413651385, 2: 0.5458900848974388},\n",
       " {0: 0.2627399109907259, 1: 0.4696838031967002, 2: 0.2675762858125738},\n",
       " {0: 0.2709640527346797, 1: 0.4140067164186604, 2: 0.3150292308466599},\n",
       " {0: 0.2006586950573654, 1: 0.2604347040677578, 2: 0.5389066008748769},\n",
       " {0: 0.552356744952427, 1: 0.24224850858381955, 2: 0.2053947464637533},\n",
       " {0: 0.25566270783173883, 1: 0.313613806152362, 2: 0.4307234860158992},\n",
       " {0: 0.5632069147063566, 1: 0.2274505002228926, 2: 0.20934258507075076},\n",
       " {0: 0.19907310979877604, 1: 0.2693539987321267, 2: 0.5315728914690973},\n",
       " {0: 0.2862293369426813, 1: 0.32719423166542166, 2: 0.38657643139189696},\n",
       " {0: 0.22675350561514626, 1: 0.25760404310656454, 2: 0.5156424512782891},\n",
       " {0: 0.17717249208913208, 1: 0.3521328731439471, 2: 0.4706946347669208},\n",
       " {0: 0.20876736156437053, 1: 0.23949773668512353, 2: 0.551734901750506},\n",
       " {0: 0.5494346301579421, 1: 0.24659032452565274, 2: 0.20397504531640517},\n",
       " {0: 0.5461274908797463, 1: 0.250444097110823, 2: 0.20342841200943054},\n",
       " {0: 0.5705629867312971, 1: 0.2193683853633795, 2: 0.21006862790532346},\n",
       " {0: 0.5746312928403103, 1: 0.21369796720106038, 2: 0.21167073995862928},\n",
       " {0: 0.3004466811175926, 1: 0.39865806455392394, 2: 0.3008952543284835},\n",
       " {0: 0.5601155769861886, 1: 0.23225113521032043, 2: 0.20763328780349097},\n",
       " {0: 0.5595779288277821, 1: 0.2336849231826061, 2: 0.20673714798961168},\n",
       " {0: 0.2010107829642442, 1: 0.31618395404727506, 2: 0.48280526298848064},\n",
       " {0: 0.3099998053586526, 1: 0.376480845561811, 2: 0.31351934907953627},\n",
       " {0: 0.562865683263438, 1: 0.2291496545725028, 2: 0.20798466216405914},\n",
       " {0: 0.5670753051461502, 1: 0.22372530919021924, 2: 0.20919938566363058},\n",
       " {0: 0.5721347772528192, 1: 0.21709508391174515, 2: 0.21077013883543563},\n",
       " {0: 0.20074820543983396, 1: 0.2737824582397091, 2: 0.525469336320457},\n",
       " {0: 0.31973215676925326, 1: 0.35074928861962695, 2: 0.32951855461111995},\n",
       " {0: 0.29848030159387207, 1: 0.39832057914556335, 2: 0.30319911926056453},\n",
       " {0: 0.5727352940844084, 1: 0.21622467548203744, 2: 0.2110400304335541},\n",
       " {0: 0.5670783845212897, 1: 0.223659229132047, 2: 0.2092623863466635},\n",
       " {0: 0.25657880150206475, 1: 0.4857136078186298, 2: 0.25770759067930543},\n",
       " {0: 0.23754586407859593, 1: 0.3895731544037694, 2: 0.37288098151763477},\n",
       " {0: 0.22065205709312946, 1: 0.28722183227699094, 2: 0.4921261106298796},\n",
       " {0: 0.2949355183738066, 1: 0.40880976370613814, 2: 0.2962547179200552},\n",
       " {0: 0.21752445787926022, 1: 0.22899541945227403, 2: 0.5534801226684656}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "sm = smax()\n",
    "\n",
    "sm.fit(X_train,y_train)\n",
    "pred = sm.predict(X_test,probas=True)\n",
    "# accuracy_score(pred, y_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7914e6",
   "metadata": {},
   "source": [
    "Неплохо"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
